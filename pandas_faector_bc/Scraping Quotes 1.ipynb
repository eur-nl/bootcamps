{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Quotes 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping : *Web scraping*, *web harvesting*, or *web data extraction* is data scraping used for extracting data from websites <a href='#[1]'>[1]</a>.\n",
    "\n",
    "The general idea behind web scraping is to retrieve data that exists on a website, and convert it into a format that is usable for analysis. Webpages are rendered by the brower from HTML and CSS code, but much of the information included in the HTML underlying any website is not interesting to us <a href='#[2]'>[2]</a>.\n",
    "\n",
    "The site we will use in this notebook is <a href=\"http://quotes.toscrape.com\">http://quotes.toscrape.com</a>.  \n",
    "\n",
    "We will use the BeautifulSoup library <a href='#[3]'>[3]</a> that will parse the source of the web page.  \n",
    "This notebook will scrape the quotes of a single page.  \n",
    "And advanced version (with pagination) are in [Scraping Quotes 2](Scraping Quotes 2.ipynb)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the needed libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single page scraping\n",
    "\n",
    "Let's start by scraping a single page of 'funny' quotes from : http://quotes.toscrape.com/tag/humor  \n",
    "On this page you'll find a list of 'funny' quotes, let's find the author and tags per quote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several libraries to get content from the web, but using ```requests``` is by far the easiest.  \n",
    "Define the URL and and get the content of the page.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"http://quotes.toscrape.com/tag/humor\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the same content we would see if we would 'View Page Source' in the browser.  \n",
    "The page is made up of elements, consisting of 'tags' with content and attributes (key/value).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```<p class=\"myclass\">This is the content</p>``` \n",
    "\n",
    "- ```<p>``` and ```</p>``` are the opening and closing tags\n",
    "- The content is between the tags\n",
    "- *class* and *myclass* are the key/value of an attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the source, we see the following structure.\n",
    "Ignoring the irrelevant parts, we see that \n",
    "- the total quote is packed in a ```<div>``` with __class=\"quote\"__\n",
    "- the quote text is in a ```<span>``` with __class=\"text\"__\n",
    "- the author is in a ```<small>``` with __class=\"author\"__\n",
    "- the tags are in a ```<a>``` with __class=\"tag\"__\n",
    "\n",
    "```\n",
    "<div class=\"quote\" ...>\n",
    "  <span class=\"text\" ...>“The actual quote”</span>\n",
    "  <span>by\n",
    "    <small class=\"author\" ...>Author name</small>\n",
    "    <a href=\"...\">(about)</a>\n",
    "  </span>\n",
    "  <div class=\"tags\">\n",
    "    Tags:\n",
    "    <meta ... /> \n",
    "    <a class=\"tag\" href=\"...\">tag 1</a>\n",
    "    <a class=\"tag\" href=\"...\">tag 2</a>\n",
    "  </div>\n",
    "</div>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all the info we want is tedious, therefor we're going to delegate this to BeautifulSoup.  \n",
    "Create a 'soup' element from the source so we can query the required elements.\n",
    "\n",
    "The ```find_all``` method searches for defined tags (optional with attributes).  \n",
    "The method returns a list (might be empty) of all the found elements.  \n",
    "To get all the quotes (there should be 10), we're going to look for a ```<div>``` with __class=\"quote\"__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the source\n",
    "page_soup = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "# We don't need the angle brackets, just the tag name\n",
    "quotes = page_soup.find_all('div', {'class': 'quote'})\n",
    "print(len(quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = quotes[0]\n",
    "print(quote.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to find the content, author and tags for this quote.  \n",
    "Again, we'll use the find_all method with the corresponding tag names and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the content, find_all returns the whole element\n",
    "# Note: we take the first element from the list\n",
    "content_element = quote.find_all('span', {'class': \"text\"})[0]\n",
    "print(content_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just want the text \n",
    "quote_text = content_element.text\n",
    "print(quote_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same for the author\n",
    "content_element = quote.find_all('small', {'class': \"author\"})[0]\n",
    "quote_author = content_element.text\n",
    "print(quote_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally the tags, find_all will find more than one\n",
    "content_elements = quote.find_all('a', {'class': \"tag\"})\n",
    "for content_element in content_elements:\n",
    "    tag = content_element.text\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quote(quote):\n",
    "    # Extract the quote text \n",
    "    content_element = quote.find_all('span', {'class': \"text\"})[0]\n",
    "    quote_text = content_element.text\n",
    "    \n",
    "    # Extract the author\n",
    "    content_element = quote.find_all('small', {'class': \"author\"})[0]\n",
    "    quote_author = content_element.text\n",
    "\n",
    "    # Extract tags\n",
    "    content_elements = quote.find_all('a', {'class': \"tag\"})\n",
    "    tags = [content_element.text for content_element in content_elements]\n",
    "    \n",
    "    print()\n",
    "    print(quote_text)\n",
    "    print(quote_author)\n",
    "    for tag in tags:\n",
    "        print(tag, end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_quote(quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First get the source of the page\n",
    "url = \"http://quotes.toscrape.com/tag/humor\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Parse the page\n",
    "page_soup = BeautifulSoup(text,'html.parser')\n",
    "\n",
    "# Loop through the quotes\n",
    "for quote in page_soup.find_all('div', {'class': 'quote'}):\n",
    "    parse_quote(quote)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='[1]'>[1]</a> https://en.wikipedia.org/wiki/Web_scraping  \n",
    "<a id='[2]'>[2]</a> https://en.wikipedia.org/wiki/HTML#Markup  \n",
    "<a id='[3]'>[3]</a> https://www.crummy.com/software/BeautifulSoup/bs4/doc/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
